# üóÇÔ∏è ShardBox

**Sistema de Arquivos Distribu√≠do Peer-to-Peer**

ShardBox √© um sistema de armazenamento distribu√≠do com 8 nodos, implementando fragmenta√ß√£o inteligente de arquivos, replica√ß√£o autom√°tica, balanceamento de carga e recupera√ß√£o de falhas.

## üìã √çndice

- [Vis√£o Geral](#-vis√£o-geral)
- [Caracter√≠sticas Principais](#-caracter√≠sticas-principais)
- [Arquitetura do Sistema](#-arquitetura-do-sistema)
- [Como Funciona](#-como-funciona)
  - [Fragmenta√ß√£o de Arquivos](#fragmenta√ß√£o-de-arquivos)
  - [Upload de Arquivos](#upload-de-arquivos)
  - [Download de Arquivos](#download-de-arquivos)
  - [Monitoramento e Heartbeat](#monitoramento-e-heartbeat)
  - [Recupera√ß√£o de Nodos](#recupera√ß√£o-de-nodos)
  - [Balanceamento de Carga](#balanceamento-de-carga)
- [Come√ßando](#-come√ßando)
- [API HTTP](#-api-http)
- [Configura√ß√£o](#Ô∏è-configura√ß√£o)
- [Estrutura de Diret√≥rios](#-estrutura-de-diret√≥rios)

---

## üéØ Vis√£o Geral

Este projeto implementa um sistema de arquivos distribu√≠do inspirado em sistemas como S3, mas usando uma arquitetura peer-to-peer simples. Cada nodo atua simultaneamente como cliente e servidor, possibilitando:

- **Fragmenta√ß√£o inteligente** baseada no tamanho do arquivo
- **Replica√ß√£o autom√°tica** para garantir disponibilidade
- **Balanceamento de carga** distribuindo fragmentos para nodos com menor uso
- **Detec√ß√£o e recupera√ß√£o autom√°tica** de nodos que falharam
- **Banco de dados compartilhado** para metadados e localiza√ß√£o de fragmentos

---

## ‚ú® Caracter√≠sticas Principais

| Caracter√≠stica | Descri√ß√£o |
|---------------|-----------|
| **üîÑ Alta Disponibilidade** | R√©plicas m√∫ltiplas garantem acesso mesmo com falhas de nodos |
| **‚öñÔ∏è Balanceamento Autom√°tico** | Distribui fragmentos baseado na carga de cada nodo |
| **‚ù§Ô∏è Monitoramento Cont√≠nuo** | Heartbeat a cada 5 segundos detecta falhas rapidamente |
| **üîß Auto-recupera√ß√£o** | Nodos mortos s√£o automaticamente reiniciados |
| **üìä Fragmenta√ß√£o Adaptativa** | Estrat√©gia de fragmenta√ß√£o varia com o tamanho do arquivo |
| **üîí Thread-Safe** | Acesso concorrente ao banco de dados protegido por locks |

---

## üèóÔ∏è Arquitetura do Sistema

![Arquitetura do Sistema](docs/architecture.png)

O sistema √© composto por **8 nodos** id√™nticos, cada um executando:

### Componentes de Cada Nodo

- **Servidor TCP (portas 5001-5008)**: Comunica√ß√£o entre nodos para heartbeat
- **Servidor HTTP (portas 8001-8008)**: Interface REST para upload/download
- **Armazenamento Local**: Diret√≥rio dedicado `files_nodo_N` para fragmentos
- **Monitor de Heartbeat**: Thread dedicada para detectar falhas
- **Logger**: Registro de eventos em `log/nodo_N.log`

### Banco de Dados Compartilhado

O arquivo `files_db.json` armazena:
- **Metadados de arquivos**: ID, nome, tamanho total
- **Localiza√ß√£o de fragmentos**: Qual nodo possui qual fragmento
- **Uso de armazenamento**: Bytes armazenados por cada nodo
- **√öltimo ID**: Contador global para IDs √∫nicos

---

## üî¨ Como Funciona

### Fragmenta√ß√£o de Arquivos

![Estrat√©gia de Fragmenta√ß√£o](docs/fragmentation-strategy.png)

A estrat√©gia de fragmenta√ß√£o varia baseada no tamanho do arquivo:

| Tamanho do Arquivo | Fragmentos | R√©plicas por Fragmento | Total de C√≥pias |
|-------------------|-----------|------------------------|-----------------|
| ‚â§ 100 bytes | 1 | 2 | 2 nodos |
| 100 bytes - 1 KB | 2 | 2 | 4 nodos |
| > 1 KB | 4 | 4 | at√© 16 c√≥pias |

**Vantagens:**
- Arquivos pequenos: m√≠nima overhead, r√°pida replica√ß√£o
- Arquivos m√©dios: balanceamento entre performance e redund√¢ncia
- Arquivos grandes: m√°xima distribui√ß√£o e paralelismo

### Upload de Arquivos

![Fluxo de Upload](docs/upload-flow.png)

**Processo de Upload:**

1. Cliente envia arquivo via `POST /upload`
2. Nodo receptor gera ID √∫nico
3. Arquivo √© fragmentado baseado no tamanho
4. Sistema consulta `armazenamento_nodo` para encontrar nodos com menor carga
5. Fragmentos s√£o distribu√≠dos via `POST /store_fragment`
6. Metadados s√£o atualizados no banco de dados compartilhado
7. Cliente recebe confirma√ß√£o com detalhes do armazenamento

**Exemplo de resposta:**
```json
{
  "id": 42,
  "filename": "documento.pdf",
  "size": 2048576,
  "fragments": 4,
  "locations": [
    {"id_nodo": 3, "id_fragmento": 0, "tamanho": 512144},
    {"id_nodo": 5, "id_fragmento": 0, "tamanho": 512144},
    ...
  ]
}
```

### Download de Arquivos

![Fluxo de Download](docs/download-flow.png)

**Processo de Download:**

1. Cliente solicita arquivo via `GET /download/{file_id}`
2. Nodo receptor consulta metadados no banco de dados
3. Para cada fragmento (em ordem):
   - Tenta buscar de qualquer r√©plica dispon√≠vel
   - Se um nodo falhar, tenta o pr√≥ximo automaticamente
4. Fragmentos s√£o concatenados na ordem correta
5. Arquivo completo √© retornado ao cliente

**Redund√¢ncia garante disponibilidade:** Mesmo se 1-3 nodos falharem, o arquivo ainda pode ser recuperado das r√©plicas.

### Monitoramento e Heartbeat

![Fluxo de Heartbeat](docs/heartbeat-flow.png)

**Sistema de Monitoramento:**

- **Intervalo:** Heartbeat enviado a cada 5 segundos (configur√°vel via `.env`)
- **Timeout:** Nodo considerado morto ap√≥s 30 segundos sem resposta
- **Protocolo:** TCP com mensagens JSON
- **Mensagem:** `{"type": "heartbeat", "node_id": N, "port": 500X}`
- **Resposta:** `{"type": "heartbeat_ack", "node_id": N, "port": 500X}`

**Detec√ß√£o de Falhas:**
```
Heartbeat OK ‚Üí Atualiza timestamp do nodo
Sem resposta ‚Üí Incrementa contador de falhas
Timeout > 30s ‚Üí Marca como MORTO ‚Üí Inicia recupera√ß√£o
```

### Recupera√ß√£o de Nodos

![Recupera√ß√£o de Nodos](docs/node-recovery.png)

**Processo de Recupera√ß√£o Autom√°tica:**

Quando um nodo √© detectado como morto, o sistema:

1. **Verifica per√≠odo de inicializa√ß√£o**: N√£o tenta recuperar nos primeiros 15 segundos
2. **Verifica cooldown**: Aguarda 60 segundos entre tentativas de recupera√ß√£o
3. **Inicia novo processo**:
   ```python
   subprocess.Popen(
       [sys.executable, 'node.py', str(id_nodo)],
       start_new_session=True  # Desacoplado do processo pai
   )
   ```
4. **Registra tentativa**: Armazena timestamp para evitar duplica√ß√£o

**Prote√ß√µes Implementadas:**
- ‚úÖ Cooldown de 60 segundos entre tentativas
- ‚úÖ Per√≠odo de gra√ßa de 15 segundos ap√≥s inicializa√ß√£o
- ‚úÖ Aguarda 10 segundos antes de iniciar monitoramento
- ‚úÖ Evita race conditions em aloca√ß√£o de portas

### Balanceamento de Carga

![Balanceamento de Carga](docs/load-balancing.png)

**Algoritmo de Distribui√ß√£o:**

1. Consulta `armazenamento_nodo` no banco de dados
2. Ordena nodos por quantidade de bytes armazenados (crescente)
3. Seleciona os N nodos com menor carga (N = n√∫mero de r√©plicas)
4. Distribui fragmento para os nodos selecionados
5. Atualiza contador de armazenamento de cada nodo

**Exemplo:**
```
Ranking atual:
1. Nodo 5: 256 KB  ‚Üê Selecionado
2. Nodo 3: 512 KB  ‚Üê Selecionado
3. Nodo 6: 768 KB
4. Nodo 2: 1024 KB
...

Para um fragmento de 100KB com 2 r√©plicas:
‚Üí Armazena em Nodo 5 (256KB ‚Üí 356KB)
‚Üí Armazena em Nodo 3 (512KB ‚Üí 612KB)
```

---

## üöÄ Come√ßando

### Pr√©-requisitos

- Python 3.8+
- pip
- Ambiente virtual (recomendado)

### Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/FabioHAraujo/ShardBox.git
cd ShardBox

# Crie e ative o ambiente virtual
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
.\venv\Scripts\activate  # Windows

# Instale as depend√™ncias
pip install -r requirements.txt
```

### Iniciar o Sistema

```bash
# Inicia todos os 8 nodos
./inicia_tudo.sh

# Verificar logs
tail -f log/nodo_*.log

# Parar todos os nodos
./mata_nodo.sh 0

# Resetar o sistema (apaga arquivos e banco de dados)
./reseta_projeto.sh
```

### Iniciar Nodos Individualmente

```bash
# Inicia um nodo espec√≠fico (1-8)
python node.py 1
```

---

## üì° API HTTP

Todos os nodos exp√µem a mesma API REST nas portas 8001-8008.

### Upload de Arquivo

**Endpoint:** `POST /upload`

**Request:**
```bash
curl -X POST -F "file=@documento.pdf" http://localhost:8001/upload
```

**Response (200 OK):**
```json
{
  "id": 42,
  "filename": "documento.pdf",
  "size": 204800,
  "fragments": 2,
  "locations": [
    {"id_nodo": 3, "id_fragmento": 0, "tamanho": 102400},
    {"id_nodo": 5, "id_fragmento": 0, "tamanho": 102400},
    {"id_nodo": 2, "id_fragmento": 1, "tamanho": 102400},
    {"id_nodo": 7, "id_fragmento": 1, "tamanho": 102400}
  ]
}
```

### Download de Arquivo

**Endpoint:** `GET /download/{file_id}`

**Request:**
```bash
curl http://localhost:8001/download/42 -o documento.pdf
```

**Response:** Arquivo bin√°rio completo

### Listar Arquivos

**Endpoint:** `GET /list`

**Request:**
```bash
curl http://localhost:8001/list
```

**Response (200 OK):**
```json
{
  "files": [
    {"id": 1, "name": "foto.jpg", "size": 512000},
    {"id": 2, "name": "video.mp4", "size": 10485760},
    {"id": 3, "name": "documento.pdf", "size": 204800}
  ]
}
```

### Armazenar Fragmento (Interno)

**Endpoint:** `POST /store_fragment`

**Uso:** Comunica√ß√£o entre nodos (n√£o destinado a uso direto)

### Buscar Fragmento (Interno)

**Endpoint:** `GET /get_fragment/{fragment_filename}`

**Uso:** Comunica√ß√£o entre nodos durante downloads

---

## ‚öôÔ∏è Configura√ß√£o

Edite o arquivo `.env` para configurar o sistema:

```bash
# Portas TCP para comunica√ß√£o entre nodos (heartbeat)
PORTAS=5001,5002,5003,5004,5005,5006,5007,5008

# Intervalo entre heartbeats (segundos)
INTERVALO_HEARTBEAT=5

# Timeout para considerar nodo offline (segundos)
TIMEOUT_HEARTBEAT=30

# Portas HTTP para API REST (cliente)
PORTAS_HTTP=8001,8002,8003,8004,8005,8006,8007,8008
```

**Par√¢metros Importantes:**

- `INTERVALO_HEARTBEAT`: Menor = detec√ß√£o mais r√°pida, maior overhead
- `TIMEOUT_HEARTBEAT`: Deve ser maior que `INTERVALO_HEARTBEAT * 2`
- Portas TCP e HTTP devem ter exatamente 8 valores (um por nodo)

---

## üìÅ Estrutura de Diret√≥rios

```
ShardBox/
‚îú‚îÄ‚îÄ node.py                    # C√≥digo principal do nodo
‚îú‚îÄ‚îÄ .env                       # Configura√ß√µes do sistema
‚îú‚îÄ‚îÄ .gitignore                 # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ inicia_tudo.sh            # Script para iniciar todos os nodos
‚îú‚îÄ‚îÄ mata_nodo.sh              # Script para parar nodos
‚îú‚îÄ‚îÄ reseta_projeto.sh         # Script para resetar o sistema
‚îú‚îÄ‚îÄ requirements.txt          # Depend√™ncias Python
‚îÇ
‚îú‚îÄ‚îÄ docs/                     # Documenta√ß√£o e diagramas
‚îÇ   ‚îú‚îÄ‚îÄ architecture.mermaid
‚îÇ   ‚îú‚îÄ‚îÄ architecture.png
‚îÇ   ‚îú‚îÄ‚îÄ download-flow.mermaid
‚îÇ   ‚îú‚îÄ‚îÄ download-flow.png
‚îÇ   ‚îú‚îÄ‚îÄ fragmentation-strategy.mermaid
‚îÇ   ‚îú‚îÄ‚îÄ fragmentation-strategy.png
‚îÇ   ‚îú‚îÄ‚îÄ heartbeat-flow.mermaid
‚îÇ   ‚îú‚îÄ‚îÄ heartbeat-flow.png
‚îÇ   ‚îú‚îÄ‚îÄ load-balancing.mermaid
‚îÇ   ‚îú‚îÄ‚îÄ load-balancing.png
‚îÇ   ‚îú‚îÄ‚îÄ node-recovery.mermaid
‚îÇ   ‚îú‚îÄ‚îÄ node-recovery.png
‚îÇ   ‚îú‚îÄ‚îÄ upload-flow.mermaid
‚îÇ   ‚îî‚îÄ‚îÄ upload-flow.png
‚îÇ
‚îú‚îÄ‚îÄ log/                      # Logs de cada nodo (gerado em runtime)
‚îÇ   ‚îú‚îÄ‚îÄ nodo_1.log
‚îÇ   ‚îú‚îÄ‚îÄ nodo_2.log
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ files_nodo_1/             # Armazenamento do nodo 1 (gerado em runtime)
‚îú‚îÄ‚îÄ files_nodo_2/             # Armazenamento do nodo 2 (gerado em runtime)
‚îú‚îÄ‚îÄ ...                       # (8 diret√≥rios no total)
‚îÇ
‚îî‚îÄ‚îÄ files_db.json             # Banco de dados compartilhado (gerado em runtime)
```

### Estrutura do `files_db.json`

```json
{
  "ultimo_id": 5,
  "arquivos": {
    "1": {
      "nome": "exemplo.txt",
      "tamanho": 150,
      "fragmentos": [
        {"id_nodo": 3, "id_fragmento": 0, "tamanho": 75},
        {"id_nodo": 5, "id_fragmento": 0, "tamanho": 75},
        {"id_nodo": 2, "id_fragmento": 1, "tamanho": 75},
        {"id_nodo": 7, "id_fragmento": 1, "tamanho": 75}
      ]
    }
  },
  "armazenamento_nodo": {
    "1": 0,
    "2": 75,
    "3": 75,
    "4": 0,
    "5": 75,
    "6": 0,
    "7": 75,
    "8": 0
  }
}
```

---

## üß™ Testando o Sistema

### Teste B√°sico de Upload/Download

```bash
# 1. Inicie o sistema
./inicia_tudo.sh

# 2. Crie um arquivo de teste
echo "Hello, Distributed World!" > teste.txt

# 3. Fa√ßa upload
curl -X POST -F "file=@teste.txt" http://localhost:8001/upload

# 4. Liste arquivos
curl http://localhost:8001/list

# 5. Fa√ßa download (use o ID retornado)
curl http://localhost:8001/download/1 -o teste_downloaded.txt

# 6. Verifique o conte√∫do
cat teste_downloaded.txt
```

### Teste de Recupera√ß√£o de Falhas

```bash
# 1. Mate um nodo espec√≠fico
./mata_nodo.sh 3

# 2. Observe os logs - outros nodos detectar√£o a falha
tail -f log/nodo_1.log

# 3. Aguarde ~30 segundos - nodo ser√° recuperado automaticamente

# 4. Verifique que o nodo voltou
tail -f log/nodo_3.log
```

### Teste de Balanceamento

```bash
# Upload m√∫ltiplos arquivos e observe a distribui√ß√£o
for i in {1..10}; do
  echo "Arquivo $i com conte√∫do vari√°vel" > file_$i.txt
  curl -X POST -F "file=@file_$i.txt" http://localhost:8001/upload
done

# Verifique o armazenamento de cada nodo
cat files_db.json | jq '.armazenamento_nodo'
```

---

## üéì Conceitos T√©cnicos

### Thread Safety

O sistema utiliza locks (`threading.Lock`) para garantir acesso thread-safe ao banco de dados compartilhado:

```python
with self.lock_bd:
    # Opera√ß√µes no files_db.json s√£o at√¥micas
    dados = json.load(f)
```

### Process Management

Recupera√ß√£o de nodos usa `subprocess.Popen` com `start_new_session=True` para desacoplar processos filhos do processo pai, garantindo que nodos recuperados sobrevivam mesmo se o nodo que iniciou a recupera√ß√£o falhar.

### Race Condition Prevention

- **Per√≠odo de gra√ßa de 10 segundos** ap√≥s inicializa√ß√£o
- **Prote√ß√£o contra recupera√ß√£o prematura** (primeiros 15 segundos)
- **Cooldown de 60 segundos** entre tentativas de recupera√ß√£o
- **Intervalo de 1 segundo** entre inicializa√ß√£o de nodos no script

---

## üìä Limita√ß√µes Conhecidas

- Banco de dados JSON √© compartilhado por arquivo (n√£o ideal para alta concorr√™ncia)
- N√£o h√° autentica√ß√£o ou autoriza√ß√£o
- Sistema assume rede local confi√°vel (localhost)
- Sem criptografia de dados em tr√¢nsito
- N√£o implementa garbage collection de fragmentos √≥rf√£os

---

## üîÆ Melhorias Futuras

- [ ] **Migrar para banco de dados distribu√≠do** onde todos os nodos mant√™m c√≥pia dos metadados, eliminando ponto √∫nico de falha:
  - **Apache Cassandra**: Alta disponibilidade, escalabilidade linear
  - **CouchDB**: Replica√ß√£o multi-master, eventual consistency
  - **Riak**: Toler√¢ncia a parti√ß√µes, modelo key-value
  - **ScyllaDB**: Alta performance, compat√≠vel com Cassandra
  - Ou implementar protocolo de consenso (Raft/Paxos) com replica√ß√£o de estado
- [ ] Implementar API de autentica√ß√£o e autoriza√ß√£o
- [ ] Adicionar compress√£o de fragmentos antes do armazenamento
- [ ] Implementar checksums (SHA-256) para verificar integridade dos fragmentos
- [ ] Dashboard web para monitoramento em tempo real do cluster
- [ ] Suporte a m√∫ltiplas m√°quinas f√≠sicas (n√£o apenas localhost)
- [ ] Implementar CRDT (Conflict-free Replicated Data Types) para sincroniza√ß√£o sem conflitos

---

## üìù Licen√ßa

Este projeto √© de c√≥digo aberto e dispon√≠vel para fins educacionais.

---

## üë• Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto em [github.com/FabioHAraujo/ShardBox](https://github.com/FabioHAraujo/ShardBox)
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

**Desenvolvido com ‚ù§Ô∏è para a mat√©ria de Sistemas Distribu√≠dos - Universidade Feevale**
